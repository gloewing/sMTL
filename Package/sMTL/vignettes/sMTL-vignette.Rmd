---
title: "sMTL Vignette"
author:
- name: Gabriel Loewinger, Kayhan Behdin, Giovanni Parmigiani, Rahul Mazumder
- name: Harvard University, Massachusetts Institute of Technology (MIT)
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    toc: yes
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
vignette: >
  %\VignetteIndexEntry{sMTL Vignette}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = "#>", warning=FALSE, message=FALSE)
```
```{r echo = FALSE}
# Thanks to Yihui Xie for providing this code
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })
```


# Introduction
`sMTL` is a fast toolkit for L0-constrained Multi-Task Learning, Multi-Label Learning and Domain Generalization. L0 constraints select the best subset of features in a variety of multi-dataset settigs. The toolkit can (approximately) solve the following two problems

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B},\bar{\boldsymbol{\beta}} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda  \sum_{k=1}^K ||\boldsymbol{\beta}_k - \bar{{\boldsymbol{\beta}}} ||_2^2 + \alpha ||\mathbb{B}||_2^2  \quad \quad (Common ~Support)  \\
    & \mbox{subject to: }~ z_{j} \in \{0,1 \} ~~ \forall ~j \in \{1,2,...,p\}  \notag \\
    & ~~~~~~~~~~~~~~~~~~~ \beta_{k,j}(1 - z_j) = 0~ \forall ~j \in \{1,2,...,p\}, k \in \{1,2,...,K\} \notag  \\
    & ~~~~~~~~~~~~~~~~~~ \sum_{j=1}^p z_j\leq s   \notag 
\end{aligned} 
$$

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B},\bar{\boldsymbol{\beta}} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda  \sum_{k=1}^K ||\boldsymbol{\beta}_k - \bar{{\boldsymbol{\beta}}} ||_2^2 + \alpha ||\mathbb{B}||_2^2 + \delta \sum_{k=1}^K ||\boldsymbol{z}_k - \bar{\boldsymbol{z}}||_2^2 \quad \quad (Heterogeneous ~Support)  \\
    & \mbox{subject to: }~ z_{k,j} \in \{0,1 \} ~~ \forall ~j \in \{1,2,...,p\} \notag \\
    & ~~~~~~~~~~~~~~~~~~~ \beta_{k,j}(1 - z_{k,j}) = 0~ \forall ~j \in \{1,2,...,p\}, k \in \{1,2,...,K\} \notag  \\
    & ~~~~~~~~~~~~~~~~~~ \sum_{j=1}^p z_{k,j}\leq s ~~\forall~ k \in \{1,2,...,K\}
\end{aligned} 
$$

where $\boldsymbol{\beta}_k$ is the vector of coefficients associated with dataset $k$, and $\boldsymbol{z}_k = \mathbb{1}_{(\boldsymbol{\beta}_k \neq \mathbf{1})}$, the ``support'' of $\boldsymbol{\beta}_k$, i.e., a $p \times 1$ indicator vector of whether the entries of $\boldsymbol{\beta}_k$ are non-zero. Note that when the variables $\boldsymbol{z}_1, ..., \boldsymbol{z}_K$ are not in the objective function, we concisely refer to the set of constraints in the above problems as the mathematically equivalent representation, $||\boldsymbol{\beta}_k||_0 \leq s~\forall~k~\in \{1,2,...,K\}$, where the $\ell_0$ norm, $||\boldsymbol{u}||_0$, equals the number of non-zero entries in the vector $\boldsymbol{u}$.

The Common Support problem ensures that each of the $K$ task-specific (or dataset-specific) $\boldsymbol{\beta}_k$ has the same support. The Heterogeneous Support problem allows each task to have a different support put penalizes the $\boldsymbol{\beta}_k$ for having differing supports using the $\delta \sum_{k=1}^K ||\boldsymbol{z}_k - \bar{\boldsymbol{z}}||_2^2$ penalty. 

The parameter $\lambda$ shrinks the $\boldsymbol{\beta}_k$ towards a common $\bar{\boldsymbol{\beta}} = \frac{1}{K}\sum_{k=1}^K \boldsymbol{\beta}_k$. The parameter $\alpha$ controls the strength of $\ell_2$ (Ridge) shrinkage where $\alpha||\mathbb{B}||_2^2 = \alpha \sum_{k=1}^K ||\boldsymbol{\beta}_k||_2^2$. Adding either of these shrinkage terms can be effective in reducing the risk of overfitting and often results in better predictive models. We recommend using either but not both of these regularization terms. For Hetergeneous Support problems $\delta$ controls the degree to which the $\boldsymbol{z}$, the supports of the $\boldsymbol{\beta}_k$, are shrunk towards $\bar{\boldsymbol{z}} = \sum_{k=1}^K \boldsymbol{z}_k$. When $\delta$ is high, this results in solutions equivalent to the Common Support approach. The fitting is done over a grid of $\lambda$, $\delta$ and $\alpha$ values to generate a regularization path. 

`sMTL` also has dedicated code to deal with the "Multi-Label Learning" (a special case of, and sometimes referred to as, "Multi-Task Learning") in which the design matrix is fixed across tasks (i.e., $\mathbb{X}_k = \mathbb{X}~\forall~k~\in\{1,2,...,K\}$), but the outcome is multivaraite. While this can be seen as a special case of the above, we include dedicated code that yields gains in efficiency in terms of memory and solve time.

The algorithms provided in `sMTL` are based on block coordinate descent and local combinatorial search. Numerous computational tricks and heuristics are used to speed up the algorithms and improve the solution quality. These heuristics include warm starts and active set convergence. For more details on the algorithms used, please refer to our paper [Fast Best Subset Selection: Coordinate Descent and Local Combinatorial Optimization Algorithms](https://pubsonline.informs.org/doi/10.1287/opre.2019.1919). 

The toolkit is implemented in Julia along with an easy-to-use R interface. In this vignette, we provide a tutorial on using the R interface. Particularly, we will demonstrate how use $\texttt{sMTL}$'s main functions for fitting models and cross-validation.

# Installation
$\texttt{sMTL}$ can be installed directly from CRAN by executing:
```{r, eval=FALSE}
install.packages("sMTL")
```
<!-- If you face installation issues, please refer to the [Installation Troubleshooting Wiki](https://github.com/hazimehh/L0Learn/wiki/Installation-Troubleshooting). If the issue is not resolved, you can submit an issue on [L0Learn's Github Repo](https://github.com/hazimehh/L0Learn). -->

The very first time we use $\texttt{sMTL}$ we have to keep in mind the following: 

# Package Setup

1. The programming language $\texttt{Julia}$ is installed. We have a function to automatically install it if it is not already:

```{r, eval = FALSE}
library(sMTL)
smtl_setup(installJulia = TRUE, installPackages = TRUE)
```

2. The $\texttt{Julia}$ packages $\texttt{TSVD}$ and $\texttt{Statistics}$ must be installed. We also have a function to automatically install these if they are not already installed. If $\texttt{Julia}$ is installed but the packages are not, the function can install them without re-installing $\texttt{Julia}$. If you ran the code for 1. above, you can ignore the rest of the set-up (1-3) and skip to fitting functions.

```{r, eval=FALSE}
library(sMTL)
smtl_setup(installJulia = FALSE, installPackages = TRUE)
```

3. The $\texttt{Julia}$ binary path must be set. If $\texttt{Julia}$ is installed with our function (item 1), this should be set automatically. If $\texttt{Julia}$ is already installed, simply open $\texttt{Julia}$ and type "println(Sys.BINDIR)" and this will show the binary path.

The following code can be used where the string (instead of <>) after the code $\texttt{path=}$ should be replaced with your computer's path for Julia's binary.
```{r, eval=FALSE}
library(sMTL)
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin")
```

The $\texttt{Julia}$ binary path is saved the first time the package is used after downloading, so one does not have to enter the path every time. Every time you load the package henceforth, one only need run the following.   
```{r, eval = TRUE}
library(sMTL)
library(L0Learn)
smtl_setup()
```
Failure to run this function above will leave R unable to locate $\texttt{Julia}$ and the package functions will not work. 

# Tutorial
To illustrate the main `sMTL` functions, we start by generating synthetic datasets and proceed by fitting models. We use terminology from Zhang & Yang, 2021. The package has three main machine learning problems it aims to solve:

1. Multi-Task Learning in which we have a collection of $K$ separate training datasets: $\{\mathbb{X}_1, \mathbb{X}_2,...,\mathbb{X}_K\}$, $\{\mathbf{y}_1, \mathbf{y}_2,...,\mathbf{y}_K\}$ where $\mathbb{X}_k \in \mathbb{R}^{n_k \times p},~ \mathbf{y}_k \in \mathbb{R}^{n_k}$. We jointly train $K$ models, one to each of the $K$ datasets with the goal of making predictions on new observations from task $k$ using model $k$.

2. Multi-Label Learning in which we have a collection of training data with a single common design matrix, $\mathbb{X}$, but a multivariate outcome for each observation, $\{\mathbf{y}_1, \mathbf{y}_2,...,\mathbf{y}_K\}$ and $\mathbb{X} \in \mathbb{R}^{n \times p}, \mathbf{y}_k \in \mathbb{R}^{n}$. We jointly train $K$ models, one to each of the $K$ datasets with the goal of making predictions on new observations from task $k$ (i.e., to predict an observation of out come $k$) using model $k$. This can be viewed as a special case of the above multi-task framework (where $\mathbb{X}_k = \mathbb{X} ~\forall k \in \{1,2,...,K\}$ but we include specialized algorithms for this case.

3. Domain Generalization in which we have a collection of $K$ separate training datasets: $\{\mathbb{X}_1, \mathbb{X}_2,...,\mathbb{X}_K\}$ and $\{\mathbf{y}_1, \mathbf{y}_2,...,\mathbf{y}_K\}$ where $\mathbb{X}_k \in \mathbb{R}^{n_k \times p},~ \mathbf{y}_k \in \mathbb{R}^{n_k}$. The goal is to make predictions on new observations from an unseen ``domain'' or dataset, $K+1$ using an ensemble of $K$ models, each trained on a single dataset. We calculate ensemble weights based upon multi-study stacking and simple average weights. The code to fit models is identical to Case 1 (Multi-Task Learning). The only difference comes in how one tunes the models and makes predictions. 

## Multi-Task Learning (Case 1)
We begin with case 1. We generate $K = 4$ synthetic datasets from a sparse linear model with the following:

* $\mathbb{X}_k$ is a $50 \times 100$ design matrix with iid standard normal entries
* $\boldsymbol{\beta}_k$ is a $50 \times 1$ vector with 10 entries set to 1 (plus some task-specific gaussian noise) and the rest are zeros. The indices of the non-zero entries differ slightly between tasks.
* $\boldsymbol{\epsilon}_k$ is a $100 \times 1$ vector with iid standard normal entries
* $\mathbf{y}_k$ is a $100 \times 1$ response vector such that $\mathbf{y}_k = \mathbb{X}_k \boldsymbol{\beta}_k + \boldsymbol{\epsilon}_k$

This dataset can be generated in R as follows:
```{r}
set.seed(1) # fix the seed to get a reproducible result
K <- 4 # number of datasets
p <- 100 # covariate dimension
s <- 5 # support size
q <- 7 # size of subset of covariates that can be non-zero for any task
n_k <- 50 # task sample size
N <- n_k * p # full dataset samplesize
X <- matrix( rnorm(N * p), nrow = N, ncol=p) # full design matrix
B <- matrix(1 + rnorm(K * (p+1) ), nrow = p + 1, ncol = K) # betas before making sparse
Z <- matrix(0, nrow = p, ncol = K) # matrix of supports
y <- vector(length = N) # outcome vector

# randomly sample support to make betas sparse
for(j in 1:K)     Z[1:q, j] <- sample( c( rep(1,s), rep(0, q - s) ), q, replace = FALSE )
B[-1,] <- B[-1,] * Z # make betas sparse and ensure all models have an intercept

task <- rep(1:K, each = n_k) # vector of task labels (indices)

# iterate through and make each task specific dataset
for(j in 1:K){
    indx <- which(task == j) # indices of task
    e <- rnorm(n_k)
    y[indx] <- B[1, j] + X[indx,] %*% B[-1,j] + e
}
```

Note that the `task` vector is a $N \times 1$ vector where element $i$ indicates the task index ($\{1,2,...,K\}$) of observation $i$.

First let's see the structure of the $\mathbb{B} \in \mathbb{R}^{p+1 \times K}$ where column $k$ is equal to $\boldsymbol{\beta}_k$. As we can see there is heterogeneity across tasks both in the support (which elements are non-zero) and in the magnitude of the coefficients. But there is enough shared structure that borrowing strength across tasks would be expected to improve performance.
```{r}
print(round(B[1:8,],2))
```

We will use $\texttt{sMTL}$ to estimate $\mathbb{B}$ from the data. 

We will start with fitting Common Support models.

###  Multi-Task Learning (Case 1): Common Support Models with Ridge Penalty
We start with the following model where we abbreviate the constraints above for conciseness.

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 \quad \quad (Common ~Support)  \\
    & \mbox{subject to: }~ ||\boldsymbol{\beta}_k ||_0 \leq s, ~\forall~k \in \{1,2,...,K\} \notag 
\end{aligned} 
$$
To fit a path of solutions for the Common Support Multi-Task model with 5 non-zero coefficients (i.e., $s=5$) and a ridge penalty $\lambda_1 = 0.001$, we use the `smtl` function and then print out the coefficients stored in $\texttt{fit}$:

```{r, eval = TRUE}
library(sMTL)
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin")

mod <- sMTL::smtl(y = y, 
                X = X, 
                study = task, 
                s = 5, 
                commonSupp = TRUE,
                lambda_1 = 0.001)

print(round(mod$beta[1:8,],2))
```

As we can see the solutions have a common support, that is each row is either all zeros or all non-zeros.

###  Multi-Task Learning (Case 1): Common Support Models with Cross-Task Coefficient Shrinkage

Let's now try a model where we shrink the $\boldsymbol{\beta}_k$ towards each other:
$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B},\bar{\boldsymbol{\beta}} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 +\lambda_2  \sum_{k=1}^K ||\boldsymbol{\beta}_k - \bar{{\boldsymbol{\beta}}} ||_2^2\quad \quad (Common ~Support)  \\
    & \mbox{subject to: }~ ||\boldsymbol{\beta}_k ||_0 \leq s, ~\forall~k \in \{1,2,...,K\} \notag 
\end{aligned} 
$$

```{r}
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = TRUE,
            lambda_2 = 0.1)

print(round(mod$beta[1:8,],2))
```

###  Multi-Task Learning (Case 1): Heterogeneous Support Models with Ridge Penalty

At times, we may not believe the supports are the same across the different $\boldsymbol{\beta}_k$. All we have to do is set `commonSupp = FALSE` and we end up with the Heterogeneous Support problem. Let's start with a simple model with a Ridge penalty:

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 \quad \quad (Heterogeneous ~Support)  \\
    & \mbox{subject to: }~ ||\boldsymbol{\beta}_k ||_0 \leq s, ~\forall~k \in \{1,2,...,K\} \notag 
\end{aligned} 
$$

```{r}
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = FALSE,
            lambda_1 = 0.001)

print(round(mod$beta[1:8,],2))
```

We can see that now many rows have a mix of zero and non-zero entries. With this model, however, we have essentially fit $K$ independent sparse regression models. In the next section, we borrow information across the supports of the models by adding in a penalty.

###  Multi-Task Learning (Case 1): Heterogeneous Support Models with Support Heterogeneity Regularization

We now shrink the supports of the $\boldsymbol{\beta}_k$, $\boldsymbol{z}_k$, towards each other. We leave the full constraints in the formulation to emphasize the role of the $\boldsymbol{z}_k$:


$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B},\bar{\boldsymbol{\beta}} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 + \lambda_z \sum_{k=1}^K ||\boldsymbol{z}_k - \bar{\boldsymbol{z}}||_2^2 \quad \quad (Heterogeneous ~Support)  \\
    & \mbox{subject to: }~ z_{k,j} \in \{0,1 \} ~~ \forall ~j \in \{1,2,...,p\} \notag \\
    & ~~~~~~~~~~~~~~~~~~~ \beta_{k,j}(1 - z_{k,j}) = 0~ \forall ~j \in \{1,2,...,p\}, k \in \{1,2,...,K\} \notag  \\
    & ~~~~~~~~~~~~~~~~~~ \sum_{j=1}^p z_{k,j}\leq s ~~\forall~ k \in \{1,2,...,K\}
\end{aligned} 
$$

```{r}
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = FALSE,
            lambda_1 = 0.001,
            lambda_z = 0.25)

print(round(mod$beta[1:8,], 2))
```

As we can see, the additional penalty reduced the support heterogeneity. Most rows are now either all zeros or all non-zeros. Now let's turn the $\lambda_z$ penalty up to show that the Common Support problem is a special case when $\lambda_z \rightarrow \infty$ (although in practice $\lambda_z$ does not need to be very big to induce a solution with a common support).

```{r}
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = FALSE,
            lambda_1 = 0.001,
            lambda_z = 10)

print(round( mod$beta[1:8,], 2))
```

###  Multi-Task Learning (Case 1): Predictions

Now that we have a model let's make predictions and see the output. We feed `predict()` a model object and some new data `X`. Here we make predictions on the training data for simplicity but in practice we would likely be more interested in predictions on new observations.

```{r, eval = FALSE}
preds <- sMTL::predict(model = mod, X = X[1:5,])
head(preds)
```

We used each model to make predictions on the new data producing a $n^* \times K$ matrix where $n^*$ is the sample size of the data we make predictions on. In practice we may only want the predictions associated with one of the tasks in which we would pick out the corresponding column.


## Multi-Label Learning (Case 2)
Multi-Label Learning can be cast as a special case of Multi-Task Learning (Case 1). The main difference here is that we can imagine that we have a single $\mathbb{X} \in \mathbb{R}^{n \times p}$ that is common to all tasks. Put another way, we have one $\mathbb{X}$ and we store all the $\mathbf{y}_k$ as columns in a matrix (i.e., a multivariate outcome, $\mathbb{Y} \in \mathbb{R}^{p \times K}$). We set $K = 4$ and generate data from a sparse linear model with the following:

* $\mathbb{X}$ is a $50 \times 100$ design matrix with iid standard normal entries
* $\boldsymbol{\beta}_k$ is a $50 \times 1$ vector with 10 entries set to 1 (plus some task-specific gaussian noise) and the rest are zeros. The indices of the non-zero entries differ slightly between tasks.
* $\boldsymbol{\epsilon}_k$ is a $100 \times 1$ vector with iid standard normal entries
* $\mathbf{y}_k$ is a $100 \times 1$ response vector such that $\mathbf{y}_k = \mathbb{X} \boldsymbol{\beta}_k + \boldsymbol{\epsilon}_k$

This dataset can be generated in R as follows:
```{r}
set.seed(1) # fix the seed to get a reproducible result
K <- 4 # number of datasets
p <- 100 # covariate dimension
s <- 5 # support size
q <- 7 # size of subset of covariates that can be non-zero for any task
N <- 50 # full dataset samplesize
X <- matrix( rnorm(N * p), nrow = N, ncol=p) # full design matrix
B <- matrix(1 + rnorm(K * (p+1) ), nrow = p + 1, ncol = K) # betas before making sparse
Z <- matrix(0, nrow = p, ncol = K) # matrix of supports
y <- matrix(nrow = N, ncol = K) # outcome vector

# randomly sample support to make betas sparse
for(j in 1:K)     Z[1:q, j] <- sample( c( rep(1,s), rep(0, q - s) ), q, replace = FALSE )
B[-1,] <- B[-1,] * Z # make betas sparse and ensure all models have an intercept

# iterate through and make each task specific dataset
for(j in 1:K){
    e <- rnorm(N)
    y[,j] <- B[1, j] + X %*% B[-1,j] + e
}
```

Note that we do not have a `task` vector here. Instead we concatenate the outcomes $\boldsymbol{y}_k$ into a matrix.

First let's see the structure of the $\mathbb{B} \in \mathbb{R}^{p+1 \times K}$ where column $k$ is equal to $\boldsymbol{\beta}_k$. As we can see there is heterogeneity across tasks both in the support (which elements are non-zero) and in the magnitude of the coefficients. But there is enough shared structure that borrowing strength across tasks would be expected to improve performance.
```{r}
print(round(B[1:8,],2))
```

We will use $\texttt{sMTL}$ to estimate $\mathbb{B}$ from the data. 

We will start with fitting Common Support models.

###  Multi-Label Learning (Case 2): Common Support Models with Ridge Penalty
We start with the following model where we abbreviate the constraints above for conciseness. 

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X} \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 \quad \quad (Common ~Support)  \\
    & \mbox{subject to: }~ ||\boldsymbol{\beta}_k ||_0 \leq s, ~\forall~k \in \{1,2,...,K\} \notag 
\end{aligned} 
$$

To fit a solutions for the Common Support Multi-Task model with 5 non-zero coefficients (i.e., $s=5$) and a Ridge penalty $\lambda_1 = 0.001$, we use the `smtl` function and then print out the coefficients stored in $\texttt{fit}$. Notice here $y$ is a matrix, and that we do not include the `study=` syntax that we use for Multi-Task learning or Domain Generalization. Otherwise the syntax is the exact same.

```{r, eval = TRUE}
mod <- sMTL::smtl(y = y, 
                X = X, 
                s = 5, 
                commonSupp = TRUE,
                lambda_1 = 0.001)

print(round(mod$beta[1:8,],2))
```

###  Multi-Label Learning (Case 2): Heterogeneous Support Models

We next show code for the Heterogeneous Support case. As we have already introduced predictions above, we include the prediction code in the same block.

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B},\bar{\boldsymbol{\beta}} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 + \lambda_z \sum_{k=1}^K ||\boldsymbol{z}_k - \bar{\boldsymbol{z}}||_2^2 \quad \quad (Heterogeneous ~Support)  \\
    & \mbox{subject to: }~ z_{k,j} \in \{0,1 \} ~~ \forall ~j \in \{1,2,...,p\} \notag \\
    & ~~~~~~~~~~~~~~~~~~~ \beta_{k,j}(1 - z_{k,j}) = 0~ \forall ~j \in \{1,2,...,p\}, k \in \{1,2,...,K\} \notag  \\
    & ~~~~~~~~~~~~~~~~~~ \sum_{j=1}^p z_{k,j}\leq s ~~\forall~ k \in \{1,2,...,K\}
\end{aligned} 
$$

```{r}
library(sMTL)
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin")


mod <- sMTL::smtl(y = y, 
                X = X, 
                s = 5, 
                commonSupp = TRUE,
                lambda_1 = 0.001,
                lambda_z = 0.1)

print(round(mod$beta[1:8,],2))

# preds <- sMTL::predict(model = mod, X = X[1:5,])
# head(preds)
```

Notice that the predictions are labeled as "task_1",...,"task_K." Since this is a ``Multi-Label'' learning problem, we would interpret "task_j" to mean "label_j."

<!-- ########################################################################## -->


## Domain-Generalization (Case 3)
The syntax and setup here is basically identical to Case 1. The main difference comes in how we tune the models and make predictions. For that reason, we include an example involving tuning, fitting and predictions.

We again generate $K = 4$ synthetic datasets from a sparse linear model with the following:

* $\mathbb{X}_k$ is a $50 \times 100$ design matrix with iid standard normal entries
* $\boldsymbol{\beta}_k$ is a $50 \times 1$ vector with 10 entries set to 1 (plus some task-specific gaussian noise) and the rest are zeros. The indices of the non-zero entries differ slightly between tasks.
* $\boldsymbol{\epsilon}_k$ is a $100 \times 1$ vector with iid standard normal entries
* $\mathbf{y}_k$ is a $100 \times 1$ response vector such that $\mathbf{y}_k = \mathbb{X}_k \boldsymbol{\beta}_k + \boldsymbol{\epsilon}_k$

This dataset can be generated in R as follows:
```{r}
set.seed(1) # fix the seed to get a reproducible result
K <- 4 # number of datasets
p <- 100 # covariate dimension
s <- 5 # support size
q <- 7 # size of subset of covariates that can be non-zero for any task
n_k <- 50 # task sample size
N <- n_k * p # full dataset samplesize
X <- matrix( rnorm(N * p), nrow = N, ncol=p) # full design matrix
B <- matrix(1 + rnorm(K * (p+1) ), nrow = p + 1, ncol = K) # betas before making sparse
Z <- matrix(0, nrow = p, ncol = K) # matrix of supports
y <- vector(length = N) # outcome vector

# randomly sample support to make betas sparse
for(j in 1:K)     Z[1:q, j] <- sample( c( rep(1,s), rep(0, q - s) ), q, replace = FALSE )
B[-1,] <- B[-1,] * Z # make betas sparse and ensure all models have an intercept

task <- rep(1:K, each = n_k) # vector of task labels (indices)

# iterate through and make each task specific dataset
for(j in 1:K){
    indx <- which(task == j) # indices of task
    e <- rnorm(n_k)
    y[indx] <- B[1, j] + X[indx,] %*% B[-1,j] + e
}
```

Note that the `task` vector is a $N \times 1$ vector where element $i$ indicates the task index ($\{1,2,...,K\}$) of observation $i$. This is equivalent to a "Domain" or "Study."

First let's see the structure of the $\mathbb{B} \in \mathbb{R}^{p+1 \times K}$ where column $k$ is equal to $\boldsymbol{\beta}_k$. As we can see there is heterogeneity across domain-specific regression coefficients both in the support (which elements are non-zero) and in the magnitude of the coefficients. But there is enough shared structure that borrowing strength across domains would be expected to improve performance.
```{r}
print(round(B[1:8,],2))
```

We will use $\texttt{sMTL}$ to estimate $\mathbb{B}$ from the data. 

We will start with fitting Common Support models.

###  Domain-Generalization (Case 3): Heterogeneous Support Model with Ridge Penalty
We start with the following model where we abbreviate the constraints above for conciseness.

$$
\begin{aligned} 
    &\underset{\boldsymbol{z},~\mathbb{B} }{\mbox{min }} \sum_{k=1}^K \frac{1}{n_k} ||  \mathbf{y}_k - \mathbb{X}_k \boldsymbol{\beta}_k ||_2^2 + \lambda_1 ||\mathbb{B}||_2^2 \quad \quad (Heterogeneous ~Support)  \\
    & \mbox{subject to: }~ ||\boldsymbol{\beta}_k ||_0 \leq s, ~\forall~k \in \{1,2,...,K\} \notag 
\end{aligned} 
$$

Here we use the same syntax from Case 1 except for 1) in the `cv.smtl` function we set `multiTask = FALSE` and 2) when making predictions, we set `stack = TRUE` in the `predict` function to use multi-study stacking to generate ensemble weights. The `predict` function then produces aggregate predictions for some new dataset or ``domain'' by either taking a weighted average of the model-specific predictions: $\hat{f}(\boldsymbol{x}) = \sum_{k=1}^K w_k \boldsymbol{x}^T \hat{\boldsymbol{\beta}}_k$. We provide the output using average weights, $w_k$, (i.e., $w_k = 1/K, \forall~ k ~ \in \{1,2,...,K\}$), or multi-study stacking weights, $w_k$.

```{r, eval = TRUE}
library(sMTL)
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin")

# tuning grid
grid <- data.frame(s = c(4, 4, 5, 5), 
                   lambda_1 = c(0.01, 0.1, 0.01, 0.1), 
                   lambda_2 = rep(0, 4), 
                   lambda_z = c(0.01, 0.1, 0.01, 0.1)
                   )

# cross validation
tn <- cv.smtl(y = y, 
              X = X, 
              study = task, 
              commonSupp = FALSE,
              grid = grid,
              nfolds = 5,
              multiTask = FALSE) 

# # model fitting
# mod <- sMTL::smtl(y = y, 
#                 X = X, 
#                 study = task, 
#                 s = tn$best.1se$s, 
#                 commonSupp = TRUE,
#                 lambda_1 = tn$best.1se$lambda_1,
#                 lambda_z = tn$best.1se$lambda_z)
# model fitting
mod <- sMTL::smtl(y = y, 
                X = X, 
                study = task, 
                s = tn$best.1se$rho, 
                commonSupp = TRUE,
                lambda_1 = tn$best.1se$lambda1,
                lambda_z = tn$best.1se$lambda_z)

# predictions
# preds <- sMTL::predict(model = mod, X = X[1:5,], stack = TRUE)
# head(preds)
```


# Cross Validation

## Basic Examples
We can use our cross validation function to tune models. The syntax is similar to the `smtl` function except one can specify an optional tuning grid, and the number of folds (`nfolds`). For Domain Generalization problems, one needs to switch `multiTask=FALSE` to change the cross validation to a hold-one-domain-out cross validation approach appropriate for the problem. 

Here we show a Multi-Task Learning problem with a custom grid and then fit a final model with the tuned hyperparameters.

```{r}
grid <- data.frame(s = c(4,4,5,5), 
                   lambda_1 = c(0.01, 0.1,0.01, 0.1), 
                   lambda_2 = 0, 
                   lambda_z = c(0.01, 0.1,0.01, 0.1))

tn <- cv.smtl(y = y, 
              X = X, 
              study = task, 
              commonSupp = FALSE,
              grid = grid,
              nfolds = 5) 

# mod <- smtl(y = y, 
#             X = X, 
#             study = task, 
#             s = tn$best$s, 
#             commonSupp = FALSE,
#             lambda_1 = tn$best$lambda_1,
#             lambda_z = tn$best$lambda_2)
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = tn$best$rho, 
            commonSupp = FALSE,
            lambda_1 = tn$best$lambda1,
            lambda_z = tn$best$lambda_z)
```

Now we show a Domain-Generalization problem with a custom grid and then fit a final model with the tuned hyperparameters. We switch `multiTask=FALSE` and proceed as normal. 

For illustrative purposes, we also choose the `best.1se` parameter values which chooses the smallest $s$ that achieves an average cross validated prediction error within 1 standard error of the parameters with the best cross validated (and the best regularization parameters for that $s$). This can result in sparser models and is an alternative option.

```{r}
grid <- data.frame(s = c(4,4,5,5), 
                   lambda_1 = c(0.01, 0.1,0.01, 0.1), 
                   lambda_2 = 0, 
                   lambda_z = c(0.01, 0.1,0.01, 0.1))

tn <- cv.smtl(y = y, 
              X = X, 
              study = task, 
              commonSupp = FALSE,
              grid = grid,
              nfolds = 5,
              multiTask = FALSE) 

# mod <- smtl(y = y, 
#             X = X, 
#             study = task, 
#             s = tn$best.1se$s, 
#             commonSupp = FALSE,
#             lambda_1 = tn$best.1se$lambda_1,
#             lambda_z = tn$best.1se$lambda_2)
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = tn$best$rho, 
            commonSupp = FALSE,
            lambda_1 = tn$best$lambda1,
            lambda_z = tn$best$lambda2)
```


## Advanced Cross Validation

There are a few advanced options for users looking to adjust the speed of the algorithms and quality of solutions. The `maxIter` argument can be increased to improve the quality of the coordinate descent algorithm or reduced to improve speed (at a cost to the solution quality). Similarly, `LocSrch_maxIter` argument specifies the number of local search iterations and increasing can improve the quality of the solutions, but can slow down the algorithm substantially. Setting `LocSrch_maxIter=0` tells the package to use no local search and may even be preferable for some problems. Finally, increasing `LocSrch_skip` to an integer above 1 will increase the speed of the algorithm by only conducting local search on a subset of parameter values on the solution path. For example, `LocSrch_skip=3` only uses local search on every $3^{rd}$ parameter value. If some local search is desirable, but one wishes to avoid using it at every parameter value because it is too slow, setting `LocSrch_skip` to somewhere between 2 and 5 could speed up cross-validation substantially while still retaining some of the benefits of local search.

## Fitting Whole Paths

Sometimes we may want to fit entire paths of solution for some fixed $s$. The algorithm is coded to fit whole paths to efficiently use warm starts to speed up the code substantially and identify better local minima. For that reason, if solutions for multiple values of tuning parameters, $(\lambda_1, \lambda_2, \lambda_z)$ are desired, it is far better to fit them jointly than to call `smtl` repeatedly. The code is almost identical except that now one or more of the tuning parameter arguments $(\lambda_1, \lambda_2, \lambda_z)$ are a vector not a scalar. Notice that $s$ is a scalar. We cannot put multiple values of $s$ in because the path of solutions is generated independently for each value of $s$.


```{r}
mod <- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = FALSE,
            lambda_1 = c(0.1, 0.2, 0.3),
            lambda_z = c(0.01, 0.05, 0.1)
            )

```

Now the solutions in `mod$beta` is a $K \times p \times T$ array where $T$ is the number of unique tuning value combinations (3 in the example above) used to fit the path of solutions.

### Predictions on Whole Path Fits

Now we many solutions so if we want to make predictions we have to specify which one or else the package will issue a warning and return no predictions.

```{r, eval = FALSE}
preds <- smtl::predict(model = mod, 
                 X = X, 
                 lambda_1 = 0.1, 
                 lambda_z = 0.01)

```
This will generate solutions for a sequence of $\lambda$ values (chosen automatically by the algorithm). To view the sequence of $\lambda$ along with the associated support sizes (i.e., the number of non-zeros), we use the `print` method as follows:
```{r, eval = FALSE}
print(fit)
```
To extract the estimated B for particular values of $\lambda$ and $\gamma$, we use the function `coef(fit,lambda,gamma)`. For example, the solution at $\lambda = 0.0325142$ (which corresponds to a support size of 10) can be extracted using
```{r output.lines=15, eval = FALSE}
coef(fit, lambda=0.0325142, gamma=0)
```

The output is a sparse vector of type `dgCMatrix`. The first element in the vector is the intercept and the rest are the B coefficients. Aside from the intercept, the only non-zeros in the above solution are coordinates 1, 2, 3, ..., 10, which are the non-zero coordinates in the true support (used to generated the data). Thus, this solution successfully recovers the true support. Note that on some BLAS implementations, the `lambda` value we used above (i.e., `0.0325142`) might be slightly different due to the limitations of numerical precision. Moreover, all the solutions in the regularization path can be extracted at once by calling `coef(fit)`.

The sequence of $\lambda$ generated by `L0Learn` is stored in the object `fit`. Specifically, `fit$lambda` is a list, where each element of the list is a sequence of $\lambda$ values corresponding to a single value of $\gamma$. Since L0 has only one value of $\gamma$ (i.e., 0), we can access the sequence of $\lambda$ values using `fit$lambda[[1]]`. Thus, $\lambda=0.0325142$ we used previously can be accessed using `fit$lambda[[1]][7]` (since it is the 7th value in the output of `print`). So the previous solution can also be extracted using `coef(fit,lambda=fit$lambda[[1]][7], gamma=0)`.

We can make predictions using a specific solution in the grid using the function `predict(fit,newx,lambda,gamma)` where newx is a testing sample (vector or matrix). For example, to predict the response for the samples in the data matrix X using the solution with $\lambda=0.0325142$, we call the prediction function as follows:
```{r output.lines=15, eval = FALSE}
predict(fit, newx=X, lambda=0.0325142, gamma=0)
```
We can also visualize the regularization path by plotting the coefficients of the estimated B versus the support size (i.e., the number of non-zeros) using the `plot(fit,gamma)` method as follows:
```{r, fig.height = 4.7, fig.width = 7, out.width="90%", dpi=300, eval = FALSE}
plot(fit, gamma=0)
```

The legend of the plot presents the variables in the order they entered the regularization path. For example, variable 7 is the first variable to enter the path, and variable 6 is the second to enter. Thus, roughly speaking, we can view the first $k$ variables in the legend as the best subset of size $k$. To show the lines connecting the points in the plot, we can set the parameter `showLines=TRUE` in the `plot` function, i.e., call `plot(fit, gamma=0, showLines=TRUE)`. Moreover, we note that the output of the `plot` function above is a `ggplot` object, which can be further customized using the `ggplot2` package. 

## Fitting L0L2 and L0L1 Regression Models
We have demonstrated the simple case of using an L0 penalty. We can also fit more elaborate models that combine L0 regularization with shrinkage-inducing penalties like the L1 norm or squared L2 norm. Adding shrinkage helps in avoiding overfitting and typically improves the predictive performance of the models. Next, we will discuss how to fit a model using the L0L2 penalty for a two-dimensional grid of $\lambda$ and $\gamma$ values. Recall that by default, `L0Learn` automatically selects the $\lambda$ sequence, so we only need to specify the $\gamma$ sequence. Suppose we want to fit an L0L2 model with a maximum of 20 non-zeros and a sequence of 5 $\gamma$ values ranging between 0.0001 and 10. We can do so by calling `L0Learn.fit` with `penalty="L0L2"`, `nGamma=5`, `gammaMin=0.0001`, and `gammaMax=10` as follows:
```{r, eval = FALSE}
fit <- L0Learn.fit(X, y, penalty="L0L2", nGamma = 5, gammaMin = 0.0001, gammaMax = 10, maxSuppSize=20)
```
`L0Learn` will generate a grid of 5 $\gamma$ values equi-spaced on the logarithmic scale between 0.0001 and 10. Similar to the case of L0, we can print a summary of the regularization path using the `print` function as follows:
```{r output.lines=30, eval = FALSE}
print(fit)
```
The sequence of $\gamma$ values can be accessed using `fit$gamma`. To extract a solution we use the `coef` method. For example, extracting the solution at $\lambda=0.0011539$ and $\gamma=10$ can be done using
```{r output.lines=15, eval = FALSE}
coef(fit,lambda=0.0011539, gamma=10)
```
Similarly, we can predict the response at this pair of $\lambda$ and $\gamma$ for the matrix X using 
```{r eval=FALSE, eval = FALSE}
predict(fit, newx=X, lambda=0.0011539, gamma=10)
```
The regularization path can also be plot at a specific $\gamma$ using `plot(fit, gamma)`. Finally, we note that fitting an L0L1 model can be done by just changing the `penalty` to "L0L1" in the above (in this case `gammaMax` will be ignored since it is automatically selected by the toolkit; see the reference manual for more details.)

## Higher-quality Solutions using Local Search
By default, `L0Learn` uses coordinate descent (CD) to fit models. Since the objective function is non-convex, the choice of the optimization algorithm can have a significant effect on the solution quality (different algorithms can lead to solutions with very different objective values). A more elaborate algorithm based on combinatorial search can be used by setting the parameter `algorithm="CDPSI"` in the call to `L0Learn.fit`. `CDPSI` typically leads to higher-quality solutions compared to CD, especially when the features are highly correlated. CDPSI is slower than CD, however, for typical applications it terminates in the order of seconds.

## Cross-validation
We will demonstrate how to use K-fold cross-validation (CV) to select the optimal values of the tuning parameters $\lambda$ and $\gamma$. To perform CV, we use the `L0Learn.cvfit` function, which takes the same parameters as `L0Learn.fit`, in addition to the number of folds using the `nFolds` parameter and a seed value using the `seed` parameter (this is used when randomly shuffling the data before performing CV). 

For example, to perform 5-fold CV using the `L0L2` penalty (over a range of 5 `gamma` values between 0.0001 and 0.1) with a maximum of 50 non-zeros, we run:
```{r, eval = FALSE}
cvfit = L0Learn.cvfit(X, y, nFolds=5, seed=1, penalty="L0L2", nGamma=5, gammaMin=0.0001, gammaMax=0.1, maxSuppSize=50)
```
Note that the object `cvfit` has a member `fit` (accessed using `cvfit$beta`) which is output of running `L0Learn.fit` on (y,X). The cross-validation errors can be accessed using the `cvMeans` attribute of `cvfit`: `cvfit$cvMeans` is a list where the ith element, `cvfit$cvMeans[[i]]`, stores the cross-validation errors for the ith value of gamma (`cvfit$beta$gamma[i]`). To find the minimum cross-validation error for every `gamma`, we call the `min` function for every element in the list `cvfit$cvMeans`, as follows:
```{r, eval = FALSE}
lapply(cvfit$cvMeans, min)
```
The above output indicates that the 4th value of gamma achieves the lowest CV error (`=0.9899542`). We can plot the CV errors against the support size for the 4th value of gamma, i.e., `gamma = cvfit$beta$gamma[4]`, using:
```{r, fig.height = 4.7, fig.width = 7, out.width="90%", dpi=300, eval = FALSE}
plot(cvfit, gamma=cvfit$beta$gamma[4])
```

The above plot is produced using the `ggplot2` package and can be further customized by the user. To extract the optimal $\lambda$ (i.e., the one with minimum CV error) in this plot, we execute the following: 
```{r, eval = FALSE}
optimalGammaIndex = 4 # index of the optimal gamma identified previously
optimalLambdaIndex = which.min(cvfit$cvMeans[[optimalGammaIndex]])
optimalLambda = cvfit$beta$lambda[[optimalGammaIndex]][optimalLambdaIndex]
optimalLambda
```
To print the solution corresponding to the optimal gamma/lambda pair:
```{r output.lines=15, eval = FALSE}
coef(cvfit, lambda=optimalLambda, gamma=cvfit$beta$gamma[4])
```
The optimal solution (above) selected by cross-validation correctly recovers the support of the true vector of coefficients used to generated the model.

## Fitting Classification Models
All the commands and plots we have seen in the case of regression extend to classification. We currently support logistic regression (using the parameter `loss = "Logistic"`) and a smoothed version of SVM (using the parameter `loss="SquaredHinge"`). To give some examples, we first generate a synthetic classification dataset (similar to the one we generated in the case of regression):
```{r, eval = FALSE}
set.seed(1) # fix the seed to get a reproducible result
X = matrix(rnorm(500*1000),nrow=500,ncol=1000)
B = c(rep(1,10),rep(0,990))
e = rnorm(500)
y = sign(X%*%B + e)
```

## Advanced Options

### User-specified Lambda Grids

# References
Yu Zhang and Qiang Yang. [A Survey on Multi-Task Learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/1707.08114&hl=en&sa=X&ei=6IbIYr7xMo-5yQTW04rIBw&scisig=AAGBfm12ecsT1Wt4UCLfp0fvnw_iHIjZ2w&oi=scholarr). IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING (2021).
